{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba9736e-9c2d-40da-9bc1-4f9319e3e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32d020a4-112b-44cf-9105-7c0f59ff8e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, char, freq):\n",
    "        self.char = char\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d1753e-83aa-4e0e-ac93-d6a5229affd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_frequency_dict(text):\n",
    "    frequency = defaultdict(int)\n",
    "    for char in text:\n",
    "        frequency[char] += 1\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9208efe4-cdff-40b8-aabc-fcdb948c36e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_huffman_tree(frequency):\n",
    "    heap = [Node(char, freq) for char, freq in frequency.items()]\n",
    "    heapq.heapify(heap)\n",
    "    \n",
    "    while len(heap) > 1:\n",
    "        left = heapq.heappop(heap)\n",
    "        right = heapq.heappop(heap)\n",
    "        \n",
    "        internal = Node(None, left.freq + right.freq)\n",
    "        internal.left = left\n",
    "        internal.right = right\n",
    "        \n",
    "        heapq.heappush(heap, internal)\n",
    "    \n",
    "    return heap[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8da4116f-fe1c-471c-9f23-44e22f319c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_codes(root, current_code, codes):\n",
    "    if root is None:\n",
    "        return\n",
    "    \n",
    "    if root.char is not None:\n",
    "        codes[root.char] = current_code\n",
    "        return\n",
    "    \n",
    "    generate_codes(root.left, current_code + \"0\", codes)\n",
    "    generate_codes(root.right, current_code + \"1\", codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c521286-b936-4c98-b153-7d519a9bd8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(text):\n",
    "    frequency = build_frequency_dict(text)\n",
    "    root = build_huffman_tree(frequency)\n",
    "    codes = {}\n",
    "    generate_codes(root, \"\", codes)\n",
    "    \n",
    "    encoded_text = \"\".join(codes[char] for char in text)\n",
    "    padding = 8 - (len(encoded_text) % 8)\n",
    "    encoded_text += \"0\" * padding\n",
    "    \n",
    "    compressed = bytearray()\n",
    "    for i in range(0, len(encoded_text), 8):\n",
    "        byte = encoded_text[i:i+8]\n",
    "        compressed.append(int(byte, 2))\n",
    "    \n",
    "    return compressed, codes, padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "114a4a68-0294-4440-98d4-962c12bb40be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompress(compressed, codes, padding):\n",
    "    reversed_codes = {code: char for char, code in codes.items()}\n",
    "    binary = \"\".join(format(byte, '08b') for byte in compressed)\n",
    "    binary = binary[:-padding]\n",
    "    \n",
    "    decoded_text = \"\"\n",
    "    current_code = \"\"\n",
    "    for bit in binary:\n",
    "        current_code += bit\n",
    "        if current_code in reversed_codes:\n",
    "            decoded_text += reversed_codes[current_code]\n",
    "            current_code = \"\"\n",
    "    \n",
    "    return decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed2008e-a6aa-4bbb-8368-044032349d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: this is an example of a huffman tree\n",
      "Compressed size: 17 bytes\n",
      "Compression ratio: 0.47\n",
      "Decompressed text: this is an example of a huffman tree\n",
      "Original and decompressed texts match: True\n"
     ]
    }
   ],
   "source": [
    "# Example usage and testing\n",
    "def main():\n",
    "    original_text = \"this is an example of a huffman tree\"\n",
    "    print(f\"Original text: {original_text}\")\n",
    "    \n",
    "    compressed, codes, padding = compress(original_text)\n",
    "    print(f\"Compressed size: {len(compressed)} bytes\")\n",
    "    print(f\"Compression ratio: {len(compressed) / len(original_text.encode('utf-8')):.2f}\")\n",
    "    \n",
    "    decompressed_text = decompress(compressed, codes, padding)\n",
    "    print(f\"Decompressed text: {decompressed_text}\")\n",
    "    print(f\"Original and decompressed texts match: {original_text == decompressed_text}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814efdca-d4ca-422a-9ca6-7929c5798051",
   "metadata": {},
   "source": [
    "### File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33f69fd0-0e1b-440d-98b9-41c3e3e86fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1318c87e-a448-4875-a922-7f62aa83ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, char, freq):\n",
    "        self.char = char\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f75defef-456c-4108-b7a1-3fa6904f585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_frequency_dict(filename):\n",
    "    frequency = defaultdict(int)\n",
    "    with open(filename, 'rb') as file:\n",
    "        while True:\n",
    "            chunk = file.read(8192)  # Read in chunks\n",
    "            if not chunk:\n",
    "                break\n",
    "            for byte in chunk:\n",
    "                frequency[byte] += 1\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03f67b42-896f-4dff-88e8-f2ad62ae778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_huffman_tree(frequency):\n",
    "    heap = [Node(char, freq) for char, freq in frequency.items()]\n",
    "    heapq.heapify(heap)\n",
    "    \n",
    "    while len(heap) > 1:\n",
    "        left = heapq.heappop(heap)\n",
    "        right = heapq.heappop(heap)\n",
    "        \n",
    "        internal = Node(None, left.freq + right.freq)\n",
    "        internal.left = left\n",
    "        internal.right = right\n",
    "        \n",
    "        heapq.heappush(heap, internal)\n",
    "    \n",
    "    return heap[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a797c33-1c73-4b12-8b6e-af434e0b3898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_codes(root, current_code, codes):\n",
    "    if root is None:\n",
    "        return\n",
    "    \n",
    "    if root.char is not None:\n",
    "        codes[root.char] = current_code\n",
    "        return\n",
    "    \n",
    "    generate_codes(root.left, current_code + \"0\", codes)\n",
    "    generate_codes(root.right, current_code + \"1\", codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "977cef82-17ad-486a-b6bd-4263e56d875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(input_file, output_file):\n",
    "    frequency = build_frequency_dict(input_file)\n",
    "    root = build_huffman_tree(frequency)\n",
    "    codes = {}\n",
    "    generate_codes(root, \"\", codes)\n",
    "    \n",
    "    with open(input_file, 'rb') as infile, open(output_file, 'wb') as outfile:\n",
    "        # Write the frequency dictionary instead of codes\n",
    "        pickle.dump(frequency, outfile)\n",
    "        \n",
    "        # Compress the file content\n",
    "        buffer = \"\"\n",
    "        compressed_data = bytearray()\n",
    "        while True:\n",
    "            chunk = infile.read(8192)\n",
    "            if not chunk:\n",
    "                break\n",
    "            for byte in chunk:\n",
    "                buffer += codes[byte]\n",
    "                while len(buffer) >= 8:\n",
    "                    compressed_data.append(int(buffer[:8], 2))\n",
    "                    buffer = buffer[8:]\n",
    "        \n",
    "        # Handle remaining bits\n",
    "        if buffer:\n",
    "            padding = 8 - len(buffer)\n",
    "            buffer += \"0\" * padding\n",
    "            compressed_data.append(int(buffer, 2))\n",
    "        else:\n",
    "            padding = 0\n",
    "        \n",
    "        # Write padding (should be a single byte)\n",
    "        outfile.write(bytes([padding]))\n",
    "        \n",
    "        # Write compressed data\n",
    "        outfile.write(compressed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4297b07a-4734-46b9-8915-6b0bede258a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompress(input_file, output_file):\n",
    "    with open(input_file, 'rb') as infile, open(output_file, 'wb') as outfile:\n",
    "        # Read the frequency dictionary\n",
    "        frequency = pickle.load(infile)\n",
    "        \n",
    "        # Rebuild the Huffman tree\n",
    "        root = build_huffman_tree(frequency)\n",
    "        codes = {}\n",
    "        generate_codes(root, \"\", codes)\n",
    "        reversed_codes = {code: bytes([char]) for char, code in codes.items()}\n",
    "        \n",
    "        # Read padding (as a single byte)\n",
    "        padding = infile.read(1)[0]\n",
    "        \n",
    "        # Read compressed data\n",
    "        compressed_data = infile.read()\n",
    "        \n",
    "        # Decompress\n",
    "        buffer = \"\"\n",
    "        for byte in compressed_data[:-1]:\n",
    "            buffer += format(byte, '08b')\n",
    "        \n",
    "        # Handle the last byte, removing the padding bits\n",
    "        last_byte = compressed_data[-1]\n",
    "        buffer += format(last_byte, '08b')[:-padding] if padding else format(last_byte, '08b')\n",
    "        \n",
    "        current_code = \"\"\n",
    "        for bit in buffer:\n",
    "            current_code += bit\n",
    "            if current_code in reversed_codes:\n",
    "                outfile.write(reversed_codes[current_code])\n",
    "                current_code = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf7ff9c6-71b4-4677-95fb-2ac105ca1537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contents of the original file:\n",
      "------------------------------------\n",
      "Embark on a thrilling journey to revolutionize exoplanet education! The discovery of exoplanets has redefined our understanding of planetary systems, expanding what we know about our place in the universe. From scorching gas giants to potentially habitable rocky worlds, these distant worlds offer a glimpse into the remarkable diversity of planetary configurations. Traditional educational materials about this topic may not be accessible to everyone, particularly those from underserved communities or with limited access to resources. Your challenge is to develop engaging and accessible learning materials that leverage creativity to enlighten students about the wonders of exoplanets.\n",
      "------------------------------------\n",
      "\n",
      "\n",
      "Contents of the compressed file:\n",
      "------------------------------------\n",
      "b'\\x80\\x04\\x95\\xbc\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x0bcollections\\x94\\x8c\\x0bdefaultdict\\x94\\x93\\x94\\x8c\\x08builtins\\x94\\x8c\\x03int\\x94\\x93\\x94\\x85\\x94R\\x94(KEK\\x01KmK\\x0cKbK\\nKaK1KrK\\'KkK\\x04K K_KoK0KnK*KtK4KhK\\x10KiK+KlK\\x1fKgK\\x0fKjK\\x01KuK\\x12KeKFKyK\\x0cKvK\\tKzK\\x01KxK\\x04KpK\\x0cKdK\\x14KcK\\x14K!K\\x01KTK\\x02KsK%KfK\\tK,K\\x03KwK\\x07K.K\\x04KFK\\x01KYK\\x01u.\\x03\\xf3\\xa6\\x93T-\\xc7\\xbbx\\x0b\\x1f\\xfc?\\xb4%\\x83W3\\xde\\xca\\xa4\\\\\\xf8\\xfa1\\xe3\\xcf4\\x86\\xc9\\x7f\\xaez\\x96\\x8d\\x9b\\xd1\\x8e\\x13\\xbe`\\x1a\\xd8F`\\xa5g\\xb8%!\\xb2_\\xeb\\x9eJ\\rJ\\xa5\\xa4Hr\\xdb\\x83Z7iT\\xedv\\xc3\\xfbpK/\\xf5\\xcfj\\xcfRt\\xe32yR\\x1a]v\\xc3\\xfb|\\x03z\\xf84+\\xe7\\x8b\\xb2`\\xfa\\xe0\\xd6\\xcb\\xfda\\xb0\\xf7\\x80h\\xde\\x05*\\x84=\\x08\\xaeMQ\\x98\\xac\\x04?\\xb7\\xddK\\xeck\\xf2^\\xcb.q~\\x8d\\xff\\xe7\\xa0\\xd9#\\xb6O\\x9a\\xb8\\xc0\\xb3\\xdf\\x18\\xbfjy^\\x01C[\\t\\xda\\xfd|b\\xfd\\xa9pA\\n\\xdd\\xbe\\xfe&\\x95\\r\\x87\\xec\\xbc\\x03T\\xcd\\xaa\\x17d\\xf9\\xad\\x81J\\xa4t\\xf7\\x04\\xb2\\xff\\\\\\xf6\\xac\\xf5\\x98\\xe2G\\xa3]\\xe8\\xc7@\\xf7\\xcc\\xba\\xd8\\xe8\\xc7\\xdf\\xd2\\xd1\\xb3z1\\xf7\\xf6m\\xe2\\xb1\\xbfK\\xb2`\\xfa\\xf0!/d\\xb0\\xcb6\\xcf_:\\xc8n\\xb1\\x85\\x12$\\xf9\\xbd\\x94\\x8aV|s\\xe5e\\xd5\\xe8`\\xff\\xab\\xf9\\xef\\x03\\x10\\xd1\\x17&\\xa3v\\x95B\\xa2\\x96\\xd6d\\xd3\\r\\xe3\\xa0\\xa5\\xc5\\xbe#\\x81\\x7f\\x13G\\x16\\xddc\\n%\\xec\\xaaS\\x06\\xac(\\x1e\\x840kX\\r\\xff\\xcb\\xfal%\\xec\\xad\"\\x9f\\xe4\\xb4\\xbf\\xbb\\xec?\\xb7]\\xb7X\\xc2\\x89\\x12|\\xdf\\x9dW\\x87\\xf6\\xcd\\xbcV7\\xe9x\\x1b\\xd7\\xe4R\\xbb\\xe9\\xacS\\xbd\\x02\\xc7O{)\\x7f\\xc7\\xa0\\xe2\\xf58m/\\xc9vL\\x1f^\\x01\\xbe1\\xdaU.\\tHl\\x97\\xfa\\xe7\\x908'\n",
      "------------------------------------\n",
      "\n",
      "Original file size: 689 bytes\n",
      "Compressed file size: 571 bytes\n",
      "\n",
      "Contents of the decompressed file:\n",
      "------------------------------------\n",
      "Embark on a thrilling journey to revolutionize exoplanet education! The discovery of exoplanets has redefined our understanding of planetary systems, expanding what we know about our place in the universe. From scorching gas giants to potentially habitable rocky worlds, these distant worlds offer a glimpse into the remarkable diversity of planetary configurations. Traditional educational materials about this topic may not be accessible to everyone, particularly those from underserved communities or with limited access to resources. Your challenge is to develop engaging and accessible learning materials that leverage creativity to enlighten students about the wonders of exoplanets.\n",
      "------------------------------------\n",
      "\n",
      "Decompression successful: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def main():\n",
    "    input_file = \"test_proj.txt\"\n",
    "    compressed_file = \"compressed.bin\"\n",
    "    decompressed_file = \"decompressed.txt\"\n",
    "    \n",
    "    # Read and print the original file\n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            original_content = f.read()\n",
    "        print(\"\\nContents of the original file:\")\n",
    "        print(\"------------------------------------\")\n",
    "        print(original_content)\n",
    "        print(\"------------------------------------\\n\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {input_file} was not found.\")\n",
    "        return\n",
    "    except IOError:\n",
    "        print(f\"Error: There was an issue reading the file {input_file}.\")\n",
    "        return\n",
    "    \n",
    "    # Compress the file\n",
    "    compress(input_file, compressed_file)\n",
    "    # Read and print the decompressed file contents\n",
    "    try:\n",
    "        with open(compressed_file, 'rb') as f:\n",
    "            compressed_content = f.read()\n",
    "        print(\"\\nContents of the compressed file:\")\n",
    "        print(\"------------------------------------\")\n",
    "        print(compressed_content)\n",
    "        print(\"------------------------------------\\n\")\n",
    "    except IOError:\n",
    "        print(f\"Error: There was an issue reading the compressed file {compressed_file}.\")\n",
    "        return\n",
    "\n",
    "    # Calculate the compressed data size\n",
    "    original_size = os.path.getsize(input_file)\n",
    "    compressed_size = os.path.getsize(compressed_file)\n",
    "    print(f\"Original file size: {original_size} bytes\")\n",
    "    print(f\"Compressed file size: {compressed_size} bytes\")\n",
    "    \n",
    "    # Decompress the file\n",
    "    decompress(compressed_file, decompressed_file)\n",
    "    \n",
    "    # Read and print the decompressed file contents\n",
    "    try:\n",
    "        with open(decompressed_file, 'r', encoding='utf-8') as f:\n",
    "            decompressed_content = f.read()\n",
    "        print(\"\\nContents of the decompressed file:\")\n",
    "        print(\"------------------------------------\")\n",
    "        print(decompressed_content)\n",
    "        print(\"------------------------------------\\n\")\n",
    "    except IOError:\n",
    "        print(f\"Error: There was an issue reading the decompressed file {decompressed_file}.\")\n",
    "        return\n",
    "    \n",
    "    # Verify the decompressed file matches the original\n",
    "    print(f\"Decompression successful: {original_content == decompressed_content}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1371dc0a-1175-4d92-b108-158db08a075d",
   "metadata": {},
   "source": [
    "## GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42c576f1-a913-499c-ae1f-c2ed6af38a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfbed56-04db-4d9a-a4ae-4f91cd020583",
   "metadata": {},
   "source": [
    "# Huffman Compression Tool Analysis\r\n",
    "\r\n",
    "## Overview\r\n",
    "This code implements a Huffman compression tool with a Gradio-based user interface. The tool allows users to compress a file using Huffman coding, decompress it, and analyze the results.\r\n",
    "\r\n",
    "## Key Components\r\n",
    "\r\n",
    "### 1. Data Structures\r\n",
    "- `Node` class: Represents a node in the Huffman tree, containing character, frequency, and left/right child information.\r\n",
    "- Frequency dictionary: Stores the frequency of each byte in the input file.\r\n",
    "- Huffman tree: Built using the frequency information to generate optimal codes.\r\n",
    "\r\n",
    "### 2. Compression Process\r\n",
    "1. Build frequency dictionary from input file.\r\n",
    "2. Construct Huffman tree based on frequencies.\r\n",
    "3. Generate Huffman codes for each byte.\r\n",
    "4. Compress input file using generated codes.\r\n",
    "5. Store frequency information and compressed data in output file.\r\n",
    "\r\n",
    "### 3. Decompression Process\r\n",
    "1. Read frequency information from compressed file.\r\n",
    "2. Reconstruct Huffman tree.\r\n",
    "3. Decode compressed data using the tree.\r\n",
    "4. Write decompressed data to output file.\r\n",
    "\r\n",
    "### 4. User Interface\r\n",
    "- Utilizes Gradio to create a web-based interface.\r\n",
    "- Allows users to upload a file for compression.\r\n",
    "- Displays compression results and offers the decompressed file for download.\r\n",
    "\r\n",
    "## Key Functions\r\n",
    "\r\n",
    "1. `build_frequency_dict(filename)`: Counts byte frequencies in the input file.\r\n",
    "2. `build_huffman_tree(frequency)`: Constructs the Huffman tree using a min-heap.\r\n",
    "3. `generate_codes(root, current_code, codes)`: Creates Huffman codes for each byte.\r\n",
    "4. `compress(input_file, output_file)`: Performs the compression process.\r\n",
    "5. `decompress(input_file, output_file)`: Performs the decompression process.\r\n",
    "6. `huffman_compression(input_file)`: Main function that handles compression, decompression, and result analysis.\r\n",
    "\r\n",
    "## Results Analysis\r\n",
    "\r\n",
    "The `huffman_compression` function provides the following results:\r\n",
    "\r\n",
    "1. Original file size (in bytes)\r\n",
    "2. Compressed file size (in bytes)\r\n",
    "3. Compression ratio (as a percentage)\r\n",
    "4. Decompression success status (boolean)\r\n",
    "\r\n",
    "These results allow users to evaluate the effectiveness of the compression for their specific files.\r\n",
    "\r\n",
    "## Potential Improvements\r\n",
    "\r\n",
    "1. Error handling: Add robust error handling for file operations and user inputs.\r\n",
    "2. Progress tracking: Implement progress bars for compression and decompression processes.\r\n",
    "3. Multi-file support: Allow compression of multiple files or entire directories.\r\n",
    "4. Adaptive Huffman coding: Implement adaptive Huffman coding for better compression of dynamic data.\r\n",
    "5. Compression options: Provide user-configurable options like block size or compression level.\r\n",
    "\r\n",
    "## Conclusion\r\n",
    "\r\n",
    "This Huffman compression tool provides a user-friendly interface for file compression using Huffman coding. It effectively demonstrates the compression algorithm's workings and provides useful metrics for analysis. With some enhancements, it could be developed into a more robust and feature-rich compression utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98f8103e-2a3a-4fb5-96ca-a4b888ce0b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, char, freq):\n",
    "        self.char = char\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq\n",
    "\n",
    "def build_frequency_dict(filename):\n",
    "    frequency = defaultdict(int)\n",
    "    with open(filename, 'rb') as file:\n",
    "        while True:\n",
    "            chunk = file.read(8192)\n",
    "            if not chunk:\n",
    "                break\n",
    "            for byte in chunk:\n",
    "                frequency[byte] += 1\n",
    "    return frequency\n",
    "\n",
    "def build_huffman_tree(frequency):\n",
    "    heap = [Node(char, freq) for char, freq in frequency.items()]\n",
    "    heapq.heapify(heap)\n",
    "    while len(heap) > 1:\n",
    "        left = heapq.heappop(heap)\n",
    "        right = heapq.heappop(heap)\n",
    "        internal = Node(None, left.freq + right.freq)\n",
    "        internal.left = left\n",
    "        internal.right = right\n",
    "        heapq.heappush(heap, internal)\n",
    "    return heap[0]\n",
    "\n",
    "def generate_codes(root, current_code, codes):\n",
    "    if root is None:\n",
    "        return\n",
    "    if root.char is not None:\n",
    "        codes[root.char] = current_code\n",
    "        return\n",
    "    generate_codes(root.left, current_code + \"0\", codes)\n",
    "    generate_codes(root.right, current_code + \"1\", codes)\n",
    "\n",
    "def compress(input_file, output_file):\n",
    "    frequency = build_frequency_dict(input_file)\n",
    "    root = build_huffman_tree(frequency)\n",
    "    codes = {}\n",
    "    generate_codes(root, \"\", codes)\n",
    "\n",
    "    with open(input_file, 'rb') as infile, open(output_file, 'wb') as outfile:\n",
    "        pickle.dump(frequency, outfile)\n",
    "        buffer = \"\"\n",
    "        compressed_data = bytearray()\n",
    "        while True:\n",
    "            chunk = infile.read(8192)\n",
    "            if not chunk:\n",
    "                break\n",
    "            for byte in chunk:\n",
    "                buffer += codes[byte]\n",
    "                while len(buffer) >= 8:\n",
    "                    compressed_data.append(int(buffer[:8], 2))\n",
    "                    buffer = buffer[8:]\n",
    "        if buffer:\n",
    "            padding = 8 - len(buffer)\n",
    "            buffer += \"0\" * padding\n",
    "            compressed_data.append(int(buffer, 2))\n",
    "        else:\n",
    "            padding = 0\n",
    "        outfile.write(bytes([padding]))\n",
    "        outfile.write(compressed_data)\n",
    "\n",
    "def decompress(input_file, output_file):\n",
    "    with open(input_file, 'rb') as infile, open(output_file, 'wb') as outfile:\n",
    "        frequency = pickle.load(infile)\n",
    "        root = build_huffman_tree(frequency)\n",
    "        codes = {}\n",
    "        generate_codes(root, \"\", codes)\n",
    "        reversed_codes = {code: bytes([char]) for char, code in codes.items()}\n",
    "        \n",
    "        padding = infile.read(1)[0]\n",
    "        compressed_data = infile.read()\n",
    "        \n",
    "        buffer = \"\"\n",
    "        for byte in compressed_data[:-1]:\n",
    "            buffer += format(byte, '08b')\n",
    "        last_byte = compressed_data[-1]\n",
    "        buffer += format(last_byte, '08b')[:-padding] if padding else format(last_byte, '08b')\n",
    "        \n",
    "        current_code = \"\"\n",
    "        for bit in buffer:\n",
    "            current_code += bit\n",
    "            if current_code in reversed_codes:\n",
    "                outfile.write(reversed_codes[current_code])\n",
    "                current_code = \"\"\n",
    "\n",
    "def huffman_compression(input_file):\n",
    "    original_size = os.path.getsize(input_file)\n",
    "    compressed_file = \"compressed.bin\"\n",
    "    decompressed_file = \"decompressed.txt\"\n",
    "\n",
    "    compress(input_file, compressed_file)\n",
    "    compressed_size = os.path.getsize(compressed_file)\n",
    "\n",
    "    decompress(compressed_file, decompressed_file)\n",
    "\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        original_content = f.read()\n",
    "    with open(decompressed_file, 'r', encoding='utf-8') as f:\n",
    "        decompressed_content = f.read()\n",
    "\n",
    "    compression_ratio = (compressed_size / original_size) * 100\n",
    "    success = original_content == decompressed_content\n",
    "\n",
    "    result = f\"\"\"Original file size: {original_size} bytes\n",
    "Compressed file size: {compressed_size} bytes\n",
    "Compression ratio: {compression_ratio:.2f}%\n",
    "Decompression successful: {success}\"\"\"\n",
    "\n",
    "    return result, decompressed_file\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=huffman_compression,\n",
    "    inputs=gr.File(label=\"Select a file to compress\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Compression Results\"),\n",
    "        gr.File(label=\"Download Decompressed File\")\n",
    "    ],\n",
    "    title=\"Huffman Compression Tool\",\n",
    "    description=\"Upload a file to compress using Huffman coding, then decompress it and download the result.\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7dc6f-19d8-4bcd-965b-91f8f1690fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c255b29c-f4c9-491d-aaf8-be64cd07fb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3ac1fd-c67f-44e7-bb9e-e21fd071cafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87526a21-3c7b-4b44-8e32-5f0057e09af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7545563b-2ad0-4961-9bab-4366ae497105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
